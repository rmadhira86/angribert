{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd04d5eedd5f2e06f254d662f0629ce674e34bb11bb4dba52a94a8659e591ad1708",
   "display_name": "Python 3.8.5 64-bit ('pyml': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# AngriBERT - Data Preparation\n",
    "Emotions data is still being created across domains. Various datasets use different classication. This Notebook, maps the datasets into the Ekman's model as close as possible. Ekman's emotion model contains six basic emotions: one positive and five negative:  \n",
    "\n",
    "joy ðŸ˜Š, anger ðŸ˜¡ disgust ðŸ¤¢ fear ðŸ˜± sadness ðŸ˜¢ surprise ðŸ˜²\n",
    "\n",
    "All the original datasets should be available in in_path location.\n",
    "\n",
    "This notebooks requires a JSON file containing a map of emotion to map to, all sub_emotions to include and a optionally the type of emotion.\n",
    "```\n",
    "{\n",
    "     # Emotion to group into\n",
    "     \"anticipation\" : \n",
    "         {   \n",
    "              #List of all of the sub-emotions that should be grouped into this emotion\n",
    "             \"sub_emotions\":[\"anticipation\", \"vigilence\"],\n",
    "              # Type of emotion   \n",
    "             \"type\":\"positive\"\n",
    "         }\n",
    "}\n",
    "```\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv \n",
    "import os\n",
    "import pandas as pd \n",
    "from collections import Counter \n"
   ]
  },
  {
   "source": [
    "## Define variables"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path = './data'                  #Location where downloaded datasets are available\n",
    "out_path = './data/final_ekman'     #Folder to write the output files into\n",
    "outstats_f = out_path + '/stats.csv'#Store statistics of the files processed \n",
    "emotion_f = './emotions_ekman.json' #File containing a map of emotions to the list of emotions into\n",
    "if not os.path.exists(out_path):    \n",
    "    os.mkdir(out_path)\n",
    "\n",
    "#Only one set of the below variables should be uncommented\n",
    "#For mapping to 11 categories\n",
    "# out_path = './data/finaldata'\n",
    "# emotion_f = './emotions.json'\n",
    " "
   ]
  },
  {
   "source": [
    "This section defines all the metadata required for processing. Only this section would need to be changed for re-runs. Rest of the code should not have any \"magic\" hardcoded values.\n",
    "\n",
    "To disable a particular dataset from being processed, comment out the lines for the corresponding metadata varable."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the below datasets \"in\" and \"out\" must have same number of elements\n",
    "# Records from the input file will be consolidated and writted into corresponding output files\n",
    "\n",
    "# SemEval 2018 dataset locations. Annotated tweets\n",
    "# Obtained from: https://competitions.codalab.org/competitions/17751\n",
    "semeval = {\"in\":[in_path + \"/semeval2018/2018-E-c-En-train.txt\",       \n",
    "                 in_path +\"/semeval2018/2018-E-c-En-dev.txt\",\n",
    "                 in_path +\"/semeval2018/2018-E-c-En-test-gold.txt\"],\n",
    "           \"out\":[out_path + \"/semeval_train.tsv\",\n",
    "                  out_path + \"/semeval_dev.tsv\",\n",
    "                  out_path + \"/semeval_test.tsv\"]      \n",
    "           }\n",
    "# Friends EmotionLines dataset location. Annotated dialogs from Friends\n",
    "# Obtained from: http://doraemon.iis.sinica.edu.tw/emotionlines/download.html\n",
    "friends = {\"in\":[in_path +\"/friends/friends_train.json\",\n",
    "                 in_path +\"/friends/friends_dev.json\",\n",
    "                 in_path +\"/friends/friends_test.json\"],\n",
    "           \"out\":[out_path + \"/friends_train.tsv\",\n",
    "                 out_path + \"/friends_dev.tsv\",\n",
    "                 out_path + \"/friends_test.tsv\"]      \n",
    "           }\n",
    "\n",
    "# GoEmotions - Annotated data of reddit comments\n",
    "# Obtained from: https://github.com/google-research/google-research/tree/master/goemotions \n",
    "# GoEmotions uses only emotion indexes in dataset. Emotions are defined in the emotions_file \n",
    "goemotions = {\"in\":[in_path +\"/goemotions/train.tsv\",\n",
    "                    in_path +\"/goemotions/dev.tsv\",\n",
    "                    in_path +\"/goemotions/test.tsv\"],\n",
    "              \"out\":[out_path + \"/goemotions_train.tsv\",\n",
    "                    out_path + \"/goemotions_dev.tsv\",\n",
    "                    out_path + \"/goemotions_test.tsv\"],\n",
    "              \"emotions_file\":in_path +\"/goemotions/emotions.txt\"      \n",
    "              }\n",
    "# Unified Dataset - multiple corpora consolidated into 9 emotions\n",
    "# Obtained from: https://github.com/sarnthil/unify-emotion-datasets \n",
    "# Unified dataset contains all data in one file. \n",
    "# We split the original file into different corpora\n",
    "# temp_path defines the folder where the split files are written to\n",
    "# top_classes: unified dataset gives the \"average\" rating for each emotion. \n",
    "#           This defines the number of \"top\" classes by rating that should be labelled\n",
    "# out_path defines where the train, dev and test for selected corpora are written to \n",
    "# out_corpora list of corpora that should be split into train, dev, test\n",
    "#           All corpora matching the strings will be split\n",
    "unified = {\"file\":in_path +\"/unified_dataset/unified-dataset.jsonl\",\n",
    "           \"temp_path\":in_path +\"/unified_dataset\",\n",
    "           \"top_classes\":2, #Number of classes with highest ratings to be assigned\n",
    "           \"out_path\":out_path,\n",
    "           \"out_corpora\":[\"tales\",\"affectivetext_\"], #List of corpus to extract\n",
    "           \"out_split\":[0.80,0.10,0.10] # Split files to into train, dev, test\n",
    "           }\n",
    "          "
   ]
  },
  {
   "source": [
    "## Class & Function definitions\n",
    "Common functions and classes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Emotions(object):\n",
    "    '''Loads emotions from a JSON file of style:\n",
    "            \"anticipation\" : \n",
    "                {   \n",
    "                    \"sub_emotions\":[\"anticipation\", \"vigilence\"],\n",
    "                    \"type\":\"positive\"\n",
    "                }\n",
    "    '''\n",
    "    def __init__(self,emotion_f):\n",
    "        with open(emotion_f) as f:\n",
    "            self.emotions_ = json.load(f)\n",
    "        self.sub_emotions_ = {v:k for k in self.emotions_.keys() \n",
    "                                    for v in self.emotions_[k]['sub_emotions']}\n",
    "        self.emo_index = {e:i for i,e in enumerate(self.emotions_.keys())}\n",
    "\n",
    "    def length(self):\n",
    "        return len(self.emo_index)\n",
    "\n",
    "    def index(self,field_name): \n",
    "        ''' Return index of summary emotion, given a sub-emotion'''   \n",
    "        return self.emo_index[self.sub_emotions_[field_name]]\n",
    "\n",
    "    def keys(self):\n",
    "        ''' Returns keys defining the list of summary emotions '''\n",
    "        return [e for e in self.emotions_.keys()]\n",
    "\n",
    "    def parent(self,field_name):\n",
    "        ''' Returns the parent emotion for a given sub sub-emotion'''\n",
    "        return self.sub_emotions_[field_name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def semeval_extract(filein, fileout):\n",
    "    ''' Processes the filein file, maps the sub-emotions from SemEval 2018 into the summary emotions defined in Emotions class \n",
    "        Args:\n",
    "        filein: string\n",
    "           Complete path for input file. Expected to be tab separated.\n",
    "        fileout: string\n",
    "           Complete path for output file. Output file is tab separated with Text and 1 Hot encoding of summary emotions\n",
    "        Returns:\n",
    "           Dictionary containing the statistics of count summary emotions in output file\n",
    "    '''\n",
    "    stats = {k:0 for k in emotions.keys()}\n",
    "    stats[\"lines\"] = 0\n",
    "    stats[\"file\"] = fileout\n",
    "    with open(filein,encoding='utf-8') as f, \\\n",
    "        open(fileout,mode=\"w\",encoding='utf-8',newline='') as fw:\n",
    "        f_read = csv.reader(f, dialect='excel',delimiter='\\t')\n",
    "        f_write = csv.writer(fw,dialect='excel',delimiter='\\t')\n",
    "        header = next(f_read)\n",
    "        #Write the header row\n",
    "        f_write.writerow(['Text']+ emotions.keys())\n",
    "        for row in f_read:\n",
    "            emo_arr = [0] * emotions.length()\n",
    "            for col in range(2,len(row)):\n",
    "                hdr,fld = header[col],row[col]\n",
    "                # If emotion is labelled as 1, mark the corresponding summary emotion as 1\n",
    "                if fld == \"1\":\n",
    "                    emo_arr[emotions.index(hdr)] = 1 \n",
    "            for i,e in enumerate(emotions.keys()):\n",
    "                stats[e] += emo_arr[i]\n",
    "            f_write.writerow([row[1]] + emo_arr)\n",
    "            stats[\"lines\"] += 1\n",
    "    return stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def friends_extract(filein,fileout):\n",
    "    ''' Processes the filein file, maps the sub-emotions from Friends dialog dataset \n",
    "        into the summary emotions defined in Emotions class \n",
    "        Args:\n",
    "        filein: string\n",
    "           Complete path for input file. Expected to be tab separated.\n",
    "        fileout: string\n",
    "           Complete path for output file. Output file is tab separated with Text and 1 Hot encoding of summary emotions\n",
    "        Returns:\n",
    "           Dictionary containing the statistics of count summary emotions in output file\n",
    "    '''\n",
    "    stats = {k:0 for k in emotions.keys()}\n",
    "    stats[\"lines\"] = 0\n",
    "    stats[\"file\"] = fileout\n",
    "    #Friends does not contain header.\n",
    "    header = [\"neutral\", \"joy\", \"sadness\", \"fear\", \"anger\", \"surprise\", \"disgust\"]\n",
    "\n",
    "    with open(filein,encoding='utf-8') as f:\n",
    "        script = json.load(f)\n",
    "    with open(fileout,mode='w',encoding='utf-8',newline='') as fw:\n",
    "        f_write = csv.writer(fw,dialect='excel',delimiter='\\t')\n",
    "        f_write.writerow(['Text'] + emotions.keys())\n",
    "        for dialogs in script:\n",
    "            for line in dialogs:\n",
    "                emo_arr = [0] * emotions.length()\n",
    "                if line['emotion'] == 'non-neutral':\n",
    "                    #When there is a conflict, the annotators have used a category non-neutral\n",
    "                    # Convert the non-neutral cases into a class with max number of annotations\n",
    "                    annots = list(line['annotation'])\n",
    "                    maxvalue = max(annots)\n",
    "                    for i in range(len(annots)):\n",
    "                        if annots[i] == maxvalue:\n",
    "                            emo_arr[emotions.index(header[i])] = 1   \n",
    "                else:\n",
    "                    emo_arr[emotions.index(line['emotion'])] = 1\n",
    "                for i,e in enumerate(emotions.keys()):\n",
    "                    stats[e] += emo_arr[i]\n",
    "                f_write.writerow([line['utterance']] + emo_arr)\n",
    "                stats[\"lines\"] += 1\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def goemotions_extract(filein,fileout,emotion_file):\n",
    "    ''' Processes the filein file, maps the sub-emotions from GoEmotions dataset \n",
    "    into the summary emotions defined in Emotions class \n",
    "    Args:\n",
    "    filein: string\n",
    "        Complete path for input file. Expected to be tab separated.\n",
    "    fileout: string\n",
    "        Complete path for output file. Output file is tab separated with Text and 1 Hot encoding of summary emotions\n",
    "    emotion_file: string\n",
    "        Complete path for file containing the list of emotions for GoEmotions. The list must the in the order of columns in filein\n",
    "    Returns:\n",
    "        Dictionary containing the statistics of count summary emotions in output file\n",
    "    '''\n",
    "    stats = {k:0 for k in emotions.keys()}\n",
    "    stats[\"lines\"] = 0\n",
    "    stats[\"file\"] = fileout\n",
    "\n",
    "    with open(emotion_file) as f:\n",
    "        header = f.read().splitlines()\n",
    "    with open(filein,mode='r',encoding='utf-8') as f, \\\n",
    "        open(fileout,mode='w',encoding='utf-8',newline='') as fw:\n",
    "\n",
    "        f_read = csv.reader(f, dialect='excel',delimiter='\\t')\n",
    "        f_write = csv.writer(fw,dialect='excel',delimiter='\\t')\n",
    "        f_write.writerow(['Text'] + emotions.keys())\n",
    "\n",
    "        for row in f_read:\n",
    "            emo_arr = [0] * emotions.length()\n",
    "            idxs = [int(idx) for idx in row[1].split(',')]\n",
    "            for idx in idxs:\n",
    "                emo_arr[emotions.index(header[idx])] = 1 \n",
    "            for i,e in enumerate(emotions.keys()):\n",
    "                stats[e] += emo_arr[i]\n",
    "            f_write.writerow([row[0]] + emo_arr)\n",
    "            stats[\"lines\"] += 1\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def unified_extract(filein,temp_path,top=2):\n",
    "    ''' Processes the filein file, maps the sub-emotions from all the corpus in Unified dataset \n",
    "        into the summary emotions defined in Emotions class. One file is produced for each corpus in the unified dataset \n",
    "        Args:\n",
    "        filein: string\n",
    "           Complete path for input file. Expected to be tab separated.\n",
    "        temp_path: string\n",
    "           Complete path where output files should be written. Must be a folder.\n",
    "           Each output file is tab separated with Text and 1 Hot encoding of summary emotions\n",
    "        top: int\n",
    "           Number of top emotions. Unified dataset gives average rating among annotators for each emotion.\n",
    "        Returns:\n",
    "           Dictionary containing the statistics of count summary emotions in output file\n",
    "    '''    \n",
    "    #Since order of corpus in input file is not guaranteed, keep a dictionary of output file handles for each corpus\n",
    "    out_files = {}\n",
    "    out_stats = []\n",
    "    with open(filein) as f:\n",
    "        prev_f = \"\"\n",
    "        for line in f:\n",
    "            d = json.loads(line)\n",
    "            fname = \"{}/{}_{}.tsv\".format(temp_path,d['source'],d['domain'])\n",
    "            if fname != prev_f:\n",
    "                if prev_f:\n",
    "                    out_stats.append(stats)\n",
    "                stats = {e:0 for e in emotions.keys()}\n",
    "                stats[\"lines\"] = 0\n",
    "                stats[\"file\"] = fname\n",
    "                prev_f = fname\n",
    "\n",
    "            # Emotions in unified dataset is given as average rating for the emotion among annotators\n",
    "            # For simplicity, pick the top 2 (default)\n",
    "            d_emo = d['emotions']\n",
    "            emo_common = Counter({k:v for k,v in d_emo.items() if v}).most_common(top)\n",
    "\n",
    "            if len(emo_common) > 0:\n",
    "                if fname not in out_files: #If we have not written to this file before, open a new handle\n",
    "                    fw = open(fname,mode='w',encoding='utf-8',newline='')\n",
    "                    f_write = csv.writer(fw,dialect='excel',delimiter='\\t')\n",
    "                    f_write.writerow(['Text'] + emotions.keys())\n",
    "                    out_files[fname] = fw,f_write\n",
    "                emo_arr = [0] * emotions.length()\n",
    "                for e in emo_common:\n",
    "                    emo_arr[emotions.index(e[0])] = 1\n",
    "                for i,e in enumerate(emotions.keys()):\n",
    "                    stats[e] += emo_arr[i]\n",
    "                stats[\"lines\"] += 1 \n",
    "                out_files[fname][1].writerow([d[\"text\"]] + emo_arr)\n",
    "        out_stats.append(stats)\n",
    "    #Close all the open output files.\n",
    "    for fw, _ in out_files.values():\n",
    "        fw.close()\n",
    "    return out_stats "
   ]
  },
  {
   "source": [
    "## Main Functions\n",
    "### Initialize variables"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = Emotions(emotion_f)\n",
    "all_stats = []"
   ]
  },
  {
   "source": [
    "### Process files \n",
    "Process files only if definitions are present. This allows multiple runs of the notebook for different datasets without overwriting previously generated dataset.  \n",
    "E.g. if you had already run SemEval and only want to run other files, comment out the definition of semeval dictionary and run the complete notebook.\n",
    "### Process SemEval Data Set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if semeval:\n",
    "    for fin,fout in zip(semeval[\"in\"],semeval[\"out\"]):\n",
    "        stats = semeval_extract(fin,fout)\n",
    "        all_stats.append(stats)"
   ]
  },
  {
   "source": [
    "### Process Friends Data Set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if friends:\n",
    "    for fin,fout in zip(friends[\"in\"],friends[\"out\"]):\n",
    "        stats = friends_extract(fin,fout)\n",
    "        all_stats.append(stats)"
   ]
  },
  {
   "source": [
    "### Process GoEmotions Data Set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if goemotions:\n",
    "    emo_f = goemotions[\"emotions_file\"]\n",
    "    for fin,fout in zip(goemotions[\"in\"],goemotions[\"out\"]):\n",
    "        stats = goemotions_extract(fin,fout,emo_f)\n",
    "        all_stats.append(stats)"
   ]
  },
  {
   "source": [
    "### Process Unified Data Set\n",
    "First split the unified dataset into different corpus files. Then for the corpus defined in **out_corpora** split the file into **train**, **dev**, **test** using the splits defined in **out_split**.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "./data/final_ekman2/tales_train.tsv ./data/final_ekman2/tales_test.tsv ./data/final_ekman2/tales_dev.tsv\n./data/final_ekman2/affectivetext__train.tsv ./data/final_ekman2/affectivetext__test.tsv ./data/final_ekman2/affectivetext__dev.tsv\n"
     ]
    }
   ],
   "source": [
    "if unified:\n",
    "    stats = unified_extract(unified[\"file\"],unified[\"temp_path\"],unified[\"top_classes\"])\n",
    "    corpus = unified.get(\"out_corpora\",[])\n",
    "    splits = unified.get(\"out_split\",[0.80,0.10,0.10])\n",
    "    out_path = unified[\"out_path\"]\n",
    "    train_size = splits[0]\n",
    "    for corp in corpus:\n",
    "        train_file = '{}/{}_{}.tsv'.format(out_path,corp,'train')\n",
    "        test_file = '{}/{}_{}.tsv'.format(out_path,corp,'test')\n",
    "        dev_file = '{}/{}_{}.tsv'.format(out_path,corp,'dev')\n",
    "        print (train_file,test_file,dev_file)\n",
    "        for s in stats:\n",
    "            if s[\"file\"].find(corp) > -1:\n",
    "                df = pd.read_csv(s[\"file\"],sep='\\t')\n",
    "                df_train = df.sample(frac=train_size).reset_index(drop=True)\n",
    "                df_train.to_csv(train_file,sep='\\t',index=False)\n",
    "                df_bal = df.drop(df_train.index).reset_index(drop=True)\n",
    "                if len(splits) == 3:\n",
    "                    dev_split = splits[1]/ sum(splits[1:])\n",
    "                    df_dev = df_bal.sample(frac=dev_split).reset_index(drop=True)\n",
    "                    df_test = df_bal.drop(df_dev.index).reset_index(drop=True)\n",
    "                    df_dev.to_csv(dev_file,sep='\\t',index=False)\n",
    "                    df_test.to_csv(test_file,sep='\\t',index=False)\n",
    "                else:\n",
    "                    df_bal.to_csv(test_file,sep='\\t',index=False)\n",
    "    all_stats += stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      joy  anger  disgust  fear  sadness  surprise  neemo   lines  \\\n",
       "0    3386   2544     2602  1242     2266       361      0    6838   \n",
       "1     489    315      319   121      292        35      0     886   \n",
       "2    1825   1101     1099   485     1049       170      0    3259   \n",
       "3    1698    960      594   424      618      1846   5823   10561   \n",
       "4     167    129       65    64       92       213    593    1178   \n",
       "5     392    275      158    95      168       465   1577    2764   \n",
       "6   19325   5579     2328   726     1864      3469  14219   43410   \n",
       "7    2434    717      289   105      212       398   1766    5426   \n",
       "8    2356    726      305    98      212       428   1787    5427   \n",
       "9     584    221      104   396      484       675      0    1246   \n",
       "10   1094   1096     1096  1095     3285         0      0    7666   \n",
       "11   1475    569     1638    91       31       251      1    4056   \n",
       "12   1530      0        0     0     1055         0      0    2585   \n",
       "13      0      0        0     0        0         0      0       0   \n",
       "14   1616   1701        0  2252     1533         0      0    7102   \n",
       "15   2354   2902      490   378     2211       160      0    4776   \n",
       "16   8237   1555      761  2816     3830      3849      0   21048   \n",
       "17  12885   1022      353   174     1150      1823  85572  102979   \n",
       "18  13040   1421      179  8430     5123      2177   9370   39740   \n",
       "19      0      0        0     0        0         0      0       0   \n",
       "20   1827    732      378   712      921       806   9395   14771   \n",
       "21    479    483       95   423      575       213      0    2268   \n",
       "\n",
       "                                                 file  \n",
       "0               ./data/final_ekman2/semeval_train.tsv  \n",
       "1                 ./data/final_ekman2/semeval_dev.tsv  \n",
       "2                ./data/final_ekman2/semeval_test.tsv  \n",
       "3               ./data/final_ekman2/friends_train.tsv  \n",
       "4                 ./data/final_ekman2/friends_dev.tsv  \n",
       "5                ./data/final_ekman2/friends_test.tsv  \n",
       "6            ./data/final_ekman2/goemotions_train.tsv  \n",
       "7              ./data/final_ekman2/goemotions_dev.tsv  \n",
       "8             ./data/final_ekman2/goemotions_test.tsv  \n",
       "9   ./data/unified_dataset/affectivetext_headlines...  \n",
       "10  ./data/unified_dataset/isear_emotional_events.tsv  \n",
       "11  ./data/unified_dataset/electoraltweets_tweets.tsv  \n",
       "12  ./data/unified_dataset/grounded_emotions_tweet...  \n",
       "13       ./data/unified_dataset/emobank_headlines.tsv  \n",
       "14           ./data/unified_dataset/emoint_tweets.tsv  \n",
       "15             ./data/unified_dataset/ssec_tweets.tsv  \n",
       "16              ./data/unified_dataset/tec_tweets.tsv  \n",
       "17  ./data/unified_dataset/dailydialog_conversatio...  \n",
       "18      ./data/unified_dataset/crowdflower_tweets.tsv  \n",
       "19  ./data/unified_dataset/fb-valence-arousal-anon...  \n",
       "20  ./data/unified_dataset/tales-emotion_fairytale...  \n",
       "21  ./data/unified_dataset/emotion-cause_artificia...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>joy</th>\n      <th>anger</th>\n      <th>disgust</th>\n      <th>fear</th>\n      <th>sadness</th>\n      <th>surprise</th>\n      <th>neemo</th>\n      <th>lines</th>\n      <th>file</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3386</td>\n      <td>2544</td>\n      <td>2602</td>\n      <td>1242</td>\n      <td>2266</td>\n      <td>361</td>\n      <td>0</td>\n      <td>6838</td>\n      <td>./data/final_ekman2/semeval_train.tsv</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>489</td>\n      <td>315</td>\n      <td>319</td>\n      <td>121</td>\n      <td>292</td>\n      <td>35</td>\n      <td>0</td>\n      <td>886</td>\n      <td>./data/final_ekman2/semeval_dev.tsv</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1825</td>\n      <td>1101</td>\n      <td>1099</td>\n      <td>485</td>\n      <td>1049</td>\n      <td>170</td>\n      <td>0</td>\n      <td>3259</td>\n      <td>./data/final_ekman2/semeval_test.tsv</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1698</td>\n      <td>960</td>\n      <td>594</td>\n      <td>424</td>\n      <td>618</td>\n      <td>1846</td>\n      <td>5823</td>\n      <td>10561</td>\n      <td>./data/final_ekman2/friends_train.tsv</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>167</td>\n      <td>129</td>\n      <td>65</td>\n      <td>64</td>\n      <td>92</td>\n      <td>213</td>\n      <td>593</td>\n      <td>1178</td>\n      <td>./data/final_ekman2/friends_dev.tsv</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>392</td>\n      <td>275</td>\n      <td>158</td>\n      <td>95</td>\n      <td>168</td>\n      <td>465</td>\n      <td>1577</td>\n      <td>2764</td>\n      <td>./data/final_ekman2/friends_test.tsv</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>19325</td>\n      <td>5579</td>\n      <td>2328</td>\n      <td>726</td>\n      <td>1864</td>\n      <td>3469</td>\n      <td>14219</td>\n      <td>43410</td>\n      <td>./data/final_ekman2/goemotions_train.tsv</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2434</td>\n      <td>717</td>\n      <td>289</td>\n      <td>105</td>\n      <td>212</td>\n      <td>398</td>\n      <td>1766</td>\n      <td>5426</td>\n      <td>./data/final_ekman2/goemotions_dev.tsv</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2356</td>\n      <td>726</td>\n      <td>305</td>\n      <td>98</td>\n      <td>212</td>\n      <td>428</td>\n      <td>1787</td>\n      <td>5427</td>\n      <td>./data/final_ekman2/goemotions_test.tsv</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>584</td>\n      <td>221</td>\n      <td>104</td>\n      <td>396</td>\n      <td>484</td>\n      <td>675</td>\n      <td>0</td>\n      <td>1246</td>\n      <td>./data/unified_dataset/affectivetext_headlines...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1094</td>\n      <td>1096</td>\n      <td>1096</td>\n      <td>1095</td>\n      <td>3285</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7666</td>\n      <td>./data/unified_dataset/isear_emotional_events.tsv</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>1475</td>\n      <td>569</td>\n      <td>1638</td>\n      <td>91</td>\n      <td>31</td>\n      <td>251</td>\n      <td>1</td>\n      <td>4056</td>\n      <td>./data/unified_dataset/electoraltweets_tweets.tsv</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>1530</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1055</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2585</td>\n      <td>./data/unified_dataset/grounded_emotions_tweet...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>./data/unified_dataset/emobank_headlines.tsv</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>1616</td>\n      <td>1701</td>\n      <td>0</td>\n      <td>2252</td>\n      <td>1533</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7102</td>\n      <td>./data/unified_dataset/emoint_tweets.tsv</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>2354</td>\n      <td>2902</td>\n      <td>490</td>\n      <td>378</td>\n      <td>2211</td>\n      <td>160</td>\n      <td>0</td>\n      <td>4776</td>\n      <td>./data/unified_dataset/ssec_tweets.tsv</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>8237</td>\n      <td>1555</td>\n      <td>761</td>\n      <td>2816</td>\n      <td>3830</td>\n      <td>3849</td>\n      <td>0</td>\n      <td>21048</td>\n      <td>./data/unified_dataset/tec_tweets.tsv</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>12885</td>\n      <td>1022</td>\n      <td>353</td>\n      <td>174</td>\n      <td>1150</td>\n      <td>1823</td>\n      <td>85572</td>\n      <td>102979</td>\n      <td>./data/unified_dataset/dailydialog_conversatio...</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>13040</td>\n      <td>1421</td>\n      <td>179</td>\n      <td>8430</td>\n      <td>5123</td>\n      <td>2177</td>\n      <td>9370</td>\n      <td>39740</td>\n      <td>./data/unified_dataset/crowdflower_tweets.tsv</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>./data/unified_dataset/fb-valence-arousal-anon...</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>1827</td>\n      <td>732</td>\n      <td>378</td>\n      <td>712</td>\n      <td>921</td>\n      <td>806</td>\n      <td>9395</td>\n      <td>14771</td>\n      <td>./data/unified_dataset/tales-emotion_fairytale...</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>479</td>\n      <td>483</td>\n      <td>95</td>\n      <td>423</td>\n      <td>575</td>\n      <td>213</td>\n      <td>0</td>\n      <td>2268</td>\n      <td>./data/unified_dataset/emotion-cause_artificia...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "df = pd.DataFrame(all_stats)\n",
    "df.to_csv(outstats_f)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}